{
  "best_global_step": 150,
  "best_metric": 2.063396453857422,
  "best_model_checkpoint": "./qwen_finetuned/checkpoint-150",
  "epoch": 4.2888086642599275,
  "eval_steps": 25,
  "global_step": 150,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.1444043321299639,
      "grad_norm": 1327.702880859375,
      "learning_rate": 0.00013333333333333334,
      "loss": 26.3113,
      "step": 5
    },
    {
      "epoch": 0.2888086642599278,
      "grad_norm": 1415.0306396484375,
      "learning_rate": 0.000199844537269886,
      "loss": 22.6039,
      "step": 10
    },
    {
      "epoch": 0.4332129963898917,
      "grad_norm": 593.2974243164062,
      "learning_rate": 0.00019889623717537564,
      "loss": 23.0594,
      "step": 15
    },
    {
      "epoch": 0.5776173285198556,
      "grad_norm": 313.7166748046875,
      "learning_rate": 0.0001970941817426052,
      "loss": 19.8893,
      "step": 20
    },
    {
      "epoch": 0.7220216606498195,
      "grad_norm": 354.9248352050781,
      "learning_rate": 0.00019445392782681522,
      "loss": 19.8984,
      "step": 25
    },
    {
      "epoch": 0.7220216606498195,
      "eval_loss": 2.2761270999908447,
      "eval_runtime": 20.2193,
      "eval_samples_per_second": 3.017,
      "eval_steps_per_second": 1.533,
      "step": 25
    },
    {
      "epoch": 0.8664259927797834,
      "grad_norm": 192.59738159179688,
      "learning_rate": 0.0001909982683161817,
      "loss": 18.6344,
      "step": 30
    },
    {
      "epoch": 1.0,
      "grad_norm": 137.81935119628906,
      "learning_rate": 0.00018675703536447178,
      "loss": 17.5164,
      "step": 35
    },
    {
      "epoch": 1.144404332129964,
      "grad_norm": 94.846435546875,
      "learning_rate": 0.00018176684285484983,
      "loss": 17.8418,
      "step": 40
    },
    {
      "epoch": 1.288808664259928,
      "grad_norm": 154.56459045410156,
      "learning_rate": 0.00017607077031810202,
      "loss": 17.3133,
      "step": 45
    },
    {
      "epoch": 1.4332129963898916,
      "grad_norm": 99.11337280273438,
      "learning_rate": 0.00016971799103396334,
      "loss": 19.4359,
      "step": 50
    },
    {
      "epoch": 1.4332129963898916,
      "eval_loss": 2.135117769241333,
      "eval_runtime": 20.1607,
      "eval_samples_per_second": 3.026,
      "eval_steps_per_second": 1.538,
      "step": 50
    },
    {
      "epoch": 1.5776173285198556,
      "grad_norm": 164.60707092285156,
      "learning_rate": 0.00016276334752608822,
      "loss": 17.0039,
      "step": 55
    },
    {
      "epoch": 1.7220216606498195,
      "grad_norm": 107.40227508544922,
      "learning_rate": 0.00015526687811534838,
      "loss": 17.6133,
      "step": 60
    },
    {
      "epoch": 1.8664259927797833,
      "grad_norm": 131.35914611816406,
      "learning_rate": 0.0001472932986186477,
      "loss": 17.5094,
      "step": 65
    },
    {
      "epoch": 2.0,
      "grad_norm": 96.48841857910156,
      "learning_rate": 0.00013891144366766456,
      "loss": 15.5422,
      "step": 70
    },
    {
      "epoch": 2.1444043321299637,
      "grad_norm": 115.82766723632812,
      "learning_rate": 0.0001301936724705278,
      "loss": 17.6656,
      "step": 75
    },
    {
      "epoch": 2.1444043321299637,
      "eval_loss": 2.147797107696533,
      "eval_runtime": 17.2115,
      "eval_samples_per_second": 3.544,
      "eval_steps_per_second": 1.801,
      "step": 75
    },
    {
      "epoch": 2.288808664259928,
      "grad_norm": 95.75904083251953,
      "learning_rate": 0.00012121524414638959,
      "loss": 17.0414,
      "step": 80
    },
    {
      "epoch": 2.4332129963898916,
      "grad_norm": 131.3057098388672,
      "learning_rate": 0.0001120536680255323,
      "loss": 16.9508,
      "step": 85
    },
    {
      "epoch": 2.577617328519856,
      "grad_norm": 117.19839477539062,
      "learning_rate": 0.00010278803452376416,
      "loss": 17.275,
      "step": 90
    },
    {
      "epoch": 2.7220216606498195,
      "grad_norm": 106.91948699951172,
      "learning_rate": 9.349833236755674e-05,
      "loss": 17.1133,
      "step": 95
    },
    {
      "epoch": 2.8664259927797833,
      "grad_norm": 161.14547729492188,
      "learning_rate": 8.426475806421138e-05,
      "loss": 17.032,
      "step": 100
    },
    {
      "epoch": 2.8664259927797833,
      "eval_loss": 2.131019353866577,
      "eval_runtime": 20.4743,
      "eval_samples_per_second": 2.979,
      "eval_steps_per_second": 1.514,
      "step": 100
    },
    {
      "epoch": 3.0,
      "grad_norm": 78.9927749633789,
      "learning_rate": 7.516702357828672e-05,
      "loss": 15.4734,
      "step": 105
    },
    {
      "epoch": 3.1444043321299637,
      "grad_norm": 98.08350372314453,
      "learning_rate": 6.628366819100585e-05,
      "loss": 16.7297,
      "step": 110
    },
    {
      "epoch": 3.288808664259928,
      "grad_norm": 73.668701171875,
      "learning_rate": 5.769138048325087e-05,
      "loss": 16.5359,
      "step": 115
    },
    {
      "epoch": 3.4332129963898916,
      "grad_norm": 89.0774917602539,
      "learning_rate": 4.9464336295355854e-05,
      "loss": 16.8953,
      "step": 120
    },
    {
      "epoch": 3.577617328519856,
      "grad_norm": 94.93206024169922,
      "learning_rate": 4.167355837898584e-05,
      "loss": 16.7141,
      "step": 125
    },
    {
      "epoch": 3.577617328519856,
      "eval_loss": 2.111936569213867,
      "eval_runtime": 20.3233,
      "eval_samples_per_second": 3.001,
      "eval_steps_per_second": 1.525,
      "step": 125
    },
    {
      "epoch": 3.7220216606498195,
      "grad_norm": 117.13922882080078,
      "learning_rate": 3.438630326912414e-05,
      "loss": 16.3422,
      "step": 130
    },
    {
      "epoch": 3.8664259927797833,
      "grad_norm": 98.40447998046875,
      "learning_rate": 2.766548066920338e-05,
      "loss": 16.7117,
      "step": 135
    },
    {
      "epoch": 4.0,
      "grad_norm": 93.50032043457031,
      "learning_rate": 2.1569110361735677e-05,
      "loss": 15.5094,
      "step": 140
    },
    {
      "epoch": 4.144404332129964,
      "grad_norm": 99.98104858398438,
      "learning_rate": 1.614982133284495e-05,
      "loss": 16.4992,
      "step": 145
    },
    {
      "epoch": 4.2888086642599275,
      "grad_norm": 89.58551788330078,
      "learning_rate": 1.1454397434679021e-05,
      "loss": 16.3039,
      "step": 150
    },
    {
      "epoch": 4.2888086642599275,
      "eval_loss": 2.063396453857422,
      "eval_runtime": 20.3083,
      "eval_samples_per_second": 3.004,
      "eval_steps_per_second": 1.526,
      "step": 150
    }
  ],
  "logging_steps": 5,
  "max_steps": 175,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 5,
  "save_steps": 50,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 4.404673944006451e+16,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
